{
  "maintainer": "RightScale, Inc.",
  "suggestions": {
  },
  "maintainer_email": "support@rightscale.com",
  "long_description": "= RightScale Database Manager\n\n== DESCRIPTION:\n\nThis cookbook provides a set of database recipes used by the RightScale \nDatabase Manager ServerTemplates.\n\nThis cookbook does not contain a specific database implementation, rather \nit provides an interface for general database actions and parameters.\n\n\n== DETAILS:\n\n=== General\nThe 'db' interface is defined by a Lightweight Resource, which can be found in\nthe resources/default.rb file.\n\nThis cookbook is intended to be used in conjunction with cookbooks that contain\nLightweight Providers which implement the 'db' interface. See the RightScale \ndb_mysql cookbook for an example.\n\nFor more about Lightweight Resources and Providers (LWRPs), please see the Chef\nwiki at:\n  \n  http://wiki.opscode.com/display/chef/Lightweight+Resources+and+Providers+%28LWRP%29\n  \n=== Backup/Restore\nThis cookbook depends on the block_device LWRP for backup and restore \nactions.  See db::do_backup and db::do_restore recipes for examples.  The \nblock_device cookbook in RightScale's cookbooks_premium repository\nprovides primary and secondary persistence solutions for multiple clouds.\n\nHowever, using LWRPs one can provide their own block_device implementation\ninstead.  \n\nPlease see RightScale's premium block_device cookbook for the list of \navailable actions, attributes and usage.\n\n      \n== REQUIREMENTS:\n\n* Must be used with a 'db' provider in the cookbook path.\n* Depends on a 'block_device' resource for backup and restore recipes. \n\n     \n== SETUP:\n   \n* Place db::default recipe into your runlist to setup the db resource.  When\n  using a RightScale ServerTemplate, this will also automatically add the \n  common database attributes to your ServerTemplate inputs.\n   \n* The default recipe for the cookbook that contains the db provider must also\n  be added to your runlist. For example:\n  \n    db_mysql::default \n    \n  This will load your provider and pull in any database specific attributes \n  as inputs.\n\n== USAGE:\n\n=== Initialize a master database:\n\n1. Once your VMs is operational, run the:\n   \n    \"db::setup_block_device\"\n    \n   recipe. This will initialize your database onto a block device\n   that supports backup and restore operations. \n2. Initialize your database from previous dumpfile or other source.\n3. Register your database with a Dynamic DNS provider using:\n#TODO update to reflect DNS changes made\n\n    \"sys_dns::do_set_private\"\n   \n   to allow you application servers to start making connections.\n4. Backup your database using:\n\n    \"db:do_backup\"\n    \n   to allow restoring the master database in case of failure or\n   planned termination.\n   \n=== Restore a master database:\n\n1. Once your VMs is operational, run the:\n   \n    \"db::do_restore\"\n    \n   recipe. This will restore your database from a backup previously saved to\n   persistent cloud storage. \n3. Register your database with a Dynamic DNS provider using:\n\n    \"sys_dns::do_set_private\"\n   \n   to allow you application servers to start making connections.\n\n\n== KNOWN LIMITATIONS:\n\n* Currently only one db provider should be present in your cookbook path.\n* The 'appserver_allow' and 'appserver_deny' recipes require VMs managed \n  by the RightScale platform to run.\n  \n   \n== PROVIDERS:\n\nWhen writing your own database Lightweight Provider:\n\n* The database provider to use is defined by node[:db][:provider] attribute, \n  you will need to override this. You can do so by adding: \n   \n    set[:db][:provider] = \"db_myprovider\"\n    \n  in the attributes file of your provider cookbook.\n  \n* Any database specific attributes that you wish to make user configurable \n  should be added to the cookbook metadata with the default recipe included in\n  the attribute's 'recipes' array.  For more about Chef metadata, please see\n  the Chef wiki at:\n  \n    http://wiki.opscode.com/display/chef/Metadata\n   \n* Your provider cookbook metadata should depend on this cookbook by\n  added a 'depends' line to your metadata. For example:\n  \n    depends \"db\"\n    \n\n\n= LICENSE\n\nCopyright RightScale, Inc. All rights reserved.  All access and use subject to the\nRightScale Terms of Service available at http://www.rightscale.com/terms.php and,\nif applicable, other agreements such as a RightScale Master Subscription Agreement.\n",
  "description": "RightScale Database Manager",
  "conflicting": {
  },
  "platforms": {
  },
  "license": "Copyright RightScale, Inc. All rights reserved.",
  "providing": {
  },
  "recipes": {
    "db::install_server": "Installs and sets up the packages that are required for database servers.",
    "db::do_set_dns_slave_private_ip": "Sets the slave DNS record to the private IP.",
    "db::setup_privileges_admin": "Adds the username and password for 'superuser' privileges.",
    "db::setup_monitoring": "Installs the collectd plugin for database monitoring support, which is required to enable monitoring and alerting functionality for your servers.",
    "db::do_secondary_init_slave": "Initializes the slave server from the secondary backup location.",
    "db::do_secondary_restore_and_become_master": "Restores the database from a secondary backup location and tags it as the master. Sets DNS. Starts a fresh backup from this master.",
    "db::install_client": "Installs the database client onto the virtual machine so that it can connect to a running server. This should be run on all database servers and servers intended to connect to the servers.",
    "db::do_appservers_allow": "Allows connections from all application servers in the deployment that are tagged with appserver:active=true tag. This script should be run on a database server so that it will accept connections from application servers.",
    "db::do_primary_backup_schedule_disable": "Disables db::do_primary_backup from being run periodically.",
    "db::request_master_deny": "Sends a request to the master database server tagged with rs_dbrepl:master_instance_uuid=<master_instance_uuid> to deny connections from the server's private IP address. This script should be run on a slave when it stops replicating.",
    "db::do_init_and_become_master": "Initializes database server and tags it as the master. Sets DNS. Starts a fresh backup from this master.",
    "db::do_appservers_deny": "Denies connections from all application servers in the deployment that are tagged with appserver:active=true tag. This script can be run on a database server to deny connections from all application servers in the deployment.",
    "db::do_dump_schedule_disable": "Disables the daily run of do_dump_export.",
    "db::do_dump_export": "Creates a dump file and uploads it to remote object storage (e.g., Amazon S3 or Rackspace Cloud Files).",
    "db::do_force_reset": "Resets the database back to a pristine state. WARNING: Execution of this script will delete any data in your database!",
    "db::setup_privileges_application": "Adds the username and password for application privileges.",
    "db::do_primary_backup_schedule_enable": "Enables db::do_primary_backup to be run periodically.",
    "db::do_primary_restore": "Restores the database from the most recently completed primary backup available in persistent storage of the current cloud.",
    "db::do_promote_to_master": "Promotes a replicating slave to master.",
    "db::do_init_slave_at_boot": "Initializes the slave server at boot.",
    "db::handle_demote_master": "Remote recipe executed by do_promote_to_master. DO NOT RUN.",
    "db::do_delete_volumes_and_terminate_server": "Deletes any currently attached volumes from the instance and then terminates the machine.",
    "db::request_master_allow": "Sends a request to the master database server tagged with rs_dbrepl:master_instance_uuid=<master_instance_uuid> to allow connections from the server's private IP address. This script should be run on a slave before it sets up replication.",
    "db::setup_replication_privileges": "Sets up privileges for replication slave servers.",
    "db::request_appserver_allow": "Sends a request to allow connections from the caller's private IP address to all database servers in the deployment that are tagged with the database:active=true tag. This should be run on an application server before attempting a database connection.",
    "db::do_dump_schedule_enable": "Schedules the daily run of do_dump_export.",
    "db::do_primary_backup": {
      "description": "Creates a primary backup of the database using persistent storage in the current cloud. On Rackspace, LVM backups are uploaded to the specified Cloud Files container. For all other clouds, volume snapshots (e.g., Amazon EBS or CloudStack volumes) are used.",
      "thread": "db_backup"
    },
    "db::do_dump_import": "Retrieves a dump file from remote object storage (e.g., Amazon S3 or Rackspace Cloud Files) and imports it to the database server.",
    "db::do_secondary_restore": "Restores the database from the most recently completed backup available in a secondary location.",
    "db::do_primary_init_slave": "Initializes the slave server from the primary backup location.",
    "db::do_primary_restore_and_become_master": "Restores the database and tags it as the master. Sets DNS. Starts a fresh backup from this master.",
    "db::request_appserver_deny": "Sends a request to deny connections from the caller's private IP address to all database servers in the deployment that are tagged with the database:active=true tag. This should be run on an application server upon decommissioning.",
    "db::do_secondary_backup": {
      "description": "Creates a backup of the database and uploads it to a secondary cloud storage location, which can be used to migrate your database to a different cloud. For example, you can save a secondary backup to an Amazon S3 bucket or a Rackspace Cloud Files container.",
      "thread": "db_backup"
    },
    "db::default": "Adds the database:active=true tag to your server, identifying it as an database server. The tag is used by application servers to identify active databases. It also loads the required 'db' resources."
  },
  "attributes": {
    "db/dns/ttl": {
      "required": "optional",
      "recipes": [
        "db::install_server"
      ],
      "description": "The upper limit for the TTL of the master DB DNS record in seconds. This value should be kept low in the event of Master DB failure so that the DNS record updates in a timely manner. When installing the DB server, this value is checked in the DNS records.",
      "display_name": "Database DNS TTL Limit",
      "type": "string",
      "choice": [

      ],
      "calculated": false
    },
    "db/init_slave_at_boot": {
      "required": "optional",
      "default": "false",
      "recipes": [
        "db::do_init_slave_at_boot"
      ],
      "description": "Set to 'True' to have the instance initialize the database server as a slave on boot. Set to 'False' if there is no master database server running.",
      "display_name": "Init Slave at Boot",
      "type": "string",
      "choice": [
        "true",
        "false"
      ],
      "calculated": false
    },
    "db/replication/password": {
      "required": "required",
      "recipes": [
        "db::setup_replication_privileges",
        "db::do_primary_restore_and_become_master",
        "db::do_secondary_restore_and_become_master",
        "db::do_init_and_become_master",
        "db::do_promote_to_master",
        "db::do_primary_init_slave",
        "db::do_secondary_init_slave",
        "db::do_init_slave_at_boot"
      ],
      "description": "The password of the database user that has 'replication' privileges (e.g., cred:DBREPLICATION_PASSWORD).",
      "display_name": "Database Replication Password",
      "type": "string",
      "choice": [

      ],
      "calculated": false
    },
    "db/admin/password": {
      "required": "required",
      "recipes": [
        "db::install_server",
        "db::setup_privileges_admin"
      ],
      "description": "The password of the database user with 'admin' privileges (e.g., cred:DBADMIN_PASSWORD).",
      "display_name": "Database Admin Password",
      "type": "string",
      "choice": [

      ],
      "calculated": false
    },
    "db/dump/database_name": {
      "required": "required",
      "recipes": [
        "db::do_dump_import",
        "db::do_dump_export",
        "db::do_dump_schedule_enable"
      ],
      "description": "Enter the name of the database name/schema to create/restore a dump from/for. Ex: mydbschema",
      "display_name": "Dump Schema/Database Name",
      "type": "string",
      "choice": [

      ],
      "calculated": false
    },
    "db/dump": {
      "required": "optional",
      "recipes": [

      ],
      "display_name": "Import/export settings for database dump file management.",
      "type": "hash",
      "choice": [

      ],
      "calculated": false
    },
    "db/backup/primary/master/cron/hour": {
      "required": "optional",
      "recipes": [
        "db::do_primary_backup_schedule_enable"
      ],
      "description": "Defines the hour of the day when the primary backup will be taken of the master database. Backups of the master are taken daily. By default, an hour will be randomly chosen at launch time. Otherwise, the time of the backup is defined by 'Master Backup Cron Hour' and 'Master Backup Cron Minute'. Uses standard crontab format (e.g., 23 for 11:00 PM).",
      "display_name": "Master Backup Cron Hour",
      "type": "string",
      "choice": [

      ],
      "calculated": false
    },
    "db/backup/timestamp_override": {
      "required": "optional",
      "recipes": [
        "db::do_primary_restore_and_become_master",
        "db::do_primary_restore",
        "db::do_primary_init_slave",
        "db::do_secondary_restore_and_become_master",
        "db::do_secondary_restore",
        "db::do_secondary_init_slave"
      ],
      "description": "An optional variable to restore a database backup with a specific timestamp rather than the most recent backup in the lineage. You must specify a string that matches the timestamp tag on the volume snapshot. You will need to specify the timestamp that is defined by the snapshot's tag (not the name). For example, if the snapshot's tag is 'rs_backup:timestamp=1303613371' you would specify '1303613371' for this input.",
      "display_name": "Database Restore Timestamp Override",
      "type": "string",
      "choice": [

      ],
      "calculated": false
    },
    "db/backup/lineage": {
      "required": "required",
      "recipes": [
        "db::do_primary_init_slave",
        "db::do_secondary_init_slave",
        "db::do_init_slave_at_boot",
        "db::do_promote_to_master",
        "db::do_primary_restore_and_become_master",
        "db::do_secondary_restore_and_become_master",
        "db::do_init_and_become_master",
        "db::do_primary_backup",
        "db::do_primary_restore",
        "db::do_primary_backup_schedule_enable",
        "db::do_primary_backup_schedule_disable",
        "db::do_force_reset",
        "db::do_secondary_backup",
        "db::do_secondary_restore"
      ],
      "description": "The prefix that will be used to name/locate the backup of a particular database. Note: For servers running on Rackspace, this value also indicates the Cloud Files container to use for storing primary backups. If a Cloud Files container with this name does not already exist, the setup process creates one.",
      "display_name": "Database Backup Lineage",
      "type": "string",
      "choice": [

      ],
      "calculated": false
    },
    "db/application/user": {
      "required": "required",
      "recipes": [
        "db::default",
        "db::setup_privileges_application"
      ],
      "description": "The username of the database user that has 'user' privileges (e.g., cred:DBAPPLICATION_USER).",
      "display_name": "Database Application Username",
      "type": "string",
      "choice": [

      ],
      "calculated": false
    },
    "db/backup/primary/master/cron/minute": {
      "required": "optional",
      "recipes": [
        "db::do_primary_backup_schedule_enable"
      ],
      "description": "Defines the minute of the hour when the backup will be taken of the master database. Backups of the master are taken daily. By default, a minute will be randomly chosen at launch time. Otherwise, the time of the backup is defined by 'Master Backup Cron Hour' and 'Master Backup Cron Minute'. Uses standard crontab format (e.g., 30 for minute 30 of the hour).",
      "display_name": "Master Backup Cron Minute",
      "type": "string",
      "choice": [

      ],
      "calculated": false
    },
    "db/dns/master/id": {
      "required": "required",
      "recipes": [
        "db::do_primary_restore_and_become_master",
        "db::do_secondary_restore_and_become_master",
        "db::do_init_and_become_master",
        "db::do_promote_to_master"
      ],
      "description": "The unique identifier that is associated with the DNS A record of the master server.  The unique identifier is assigned by the DNS provider when you create a dynamic DNS A record. This ID is used to update the associated A record with the private IP address of the master server when this recipe is run.  If you are using DNS Made Easy as your DNS provider, a 7-digit number is used (e.g., 4403234).",
      "display_name": "Database Master DNS Record ID",
      "type": "string",
      "choice": [

      ],
      "calculated": false
    },
    "db/force_safety": {
      "required": "optional",
      "default": "Override the dropdown and set to \"off\" to really run this recipe",
      "recipes": [
        "db::do_force_reset"
      ],
      "description": "Prevents the accidental running of the db::do_force_reset recipe. This recipe will only run if the input variable is overridden and set to \"off\".",
      "display_name": "Force Reset Safety",
      "type": "string",
      "choice": [
        "Override the dropdown and set to \"off\" to really run this recipe"
      ],
      "calculated": false
    },
    "db/dump/container": {
      "required": "required",
      "recipes": [
        "db::do_dump_import",
        "db::do_dump_export",
        "db::do_dump_schedule_enable"
      ],
      "description": "The cloud storage location where the dump file will be saved to or restored from. For Amazon S3, use the bucket name. For Rackspace Cloud Files, use the container name.",
      "display_name": "Dump Container",
      "type": "string",
      "choice": [

      ],
      "calculated": false
    },
    "db/backup/lineage_override": {
      "required": "optional",
      "recipes": [
        "db::do_init_slave_at_boot",
        "db::do_primary_restore_and_become_master",
        "db::do_primary_restore",
        "db::do_primary_init_slave",
        "db::do_secondary_restore_and_become_master",
        "db::do_secondary_restore",
        "db::do_secondary_init_slave"
      ],
      "description": "If defined, this will override the input defined for 'Backup Lineage' (db/backup/lineage) so that you can restore the database from another backup that has as different lineage name. The most recently completed snapshots will be used unless a specific timestamp value is specified for 'Restore Timestamp Override' (db/backup/timestamp_override). Although this input allows you to restore from a different set of snapshots, subsequent backups will use 'Backup Lineage' to name the snapshots. Be sure to remove the 'Backup Lineage Override' input after the new master is operational.",
      "display_name": "Database Restore Lineage Override",
      "type": "string",
      "choice": [

      ],
      "calculated": false
    },
    "db/application/password": {
      "required": "required",
      "recipes": [
        "db::default",
        "db::setup_privileges_application"
      ],
      "description": "The password of the database user that has 'user' privileges (e.g., cred:DBAPPLICATION_PASSWORD).",
      "display_name": "Database Application Password",
      "type": "string",
      "choice": [

      ],
      "calculated": false
    },
    "db/dns/master/fqdn": {
      "required": "required",
      "recipes": [
        "db::default"
      ],
      "description": "The fully qualified domain name for the master database server (e.g., text:db-master.example.com).",
      "display_name": "Database Master FQDN",
      "type": "string",
      "choice": [

      ],
      "calculated": false
    },
    "db/dump/prefix": {
      "required": "required",
      "recipes": [
        "db::do_dump_import",
        "db::do_dump_export",
        "db::do_dump_schedule_enable"
      ],
      "description": "The prefix that will be used to name/locate the backup of a particular database dump. Defines the prefix of the dump file name that will be used to name the backup database dump file, along with a timestamp.",
      "display_name": "Dump Prefix",
      "type": "string",
      "choice": [

      ],
      "calculated": false
    },
    "db/dump/storage_account_secret": {
      "required": "required",
      "recipes": [
        "db::do_dump_import",
        "db::do_dump_export",
        "db::do_dump_schedule_enable"
      ],
      "description": "In order to write the dump file to the specified cloud storage location, you will need to provide cloud authentication credentials. For Amazon S3, use your AWS secret access key (e.g., cred:AWS_SECRET_ACCESS_KEY). For Rackspace Cloud Files, use your Rackspace account API key (e.g., cred:RACKSPACE_AUTH_KEY).",
      "display_name": "Dump Storage Account Secret",
      "type": "string",
      "choice": [

      ],
      "calculated": false
    },
    "db/backup/primary/slave/cron/minute": {
      "required": "optional",
      "recipes": [
        "db::do_primary_backup_schedule_enable"
      ],
      "description": "Defines the minute of the hour when the backup EBS snapshot will be taken of the Slave database. Backups of the Slave are taken hourly. By default, a minute will be randomly chosen at launch time. Uses standard crontab format (e.g., 30 for minute 30 of the hour).",
      "display_name": "Slave Backup Cron Minute",
      "type": "string",
      "choice": [

      ],
      "calculated": false
    },
    "db/backup/primary/slave/cron/hour": {
      "required": "optional",
      "recipes": [
        "db::do_primary_backup_schedule_enable"
      ],
      "description": "By default, primary backups of the slave database are taken hourly. However, if you specify a value in this input (e.g., 23 for 11:00 PM), then backups will occur once per day at the specified hour, rather than hourly.",
      "display_name": "Slave Backup Cron Hour",
      "type": "string",
      "choice": [

      ],
      "calculated": false
    },
    "db/admin/user": {
      "required": "required",
      "recipes": [
        "db::install_server",
        "db::setup_privileges_admin"
      ],
      "description": "The username of the database user with 'admin' privileges (e.g., cred:DBADMIN_USER).",
      "display_name": "Database Admin Username",
      "type": "string",
      "choice": [

      ],
      "calculated": false
    },
    "db": {
      "required": "optional",
      "recipes": [

      ],
      "display_name": "General Database Options",
      "type": "hash",
      "choice": [

      ],
      "calculated": false
    },
    "db/dump/storage_account_id": {
      "required": "required",
      "recipes": [
        "db::do_dump_import",
        "db::do_dump_export",
        "db::do_dump_schedule_enable"
      ],
      "description": "In order to write the dump file to the specified cloud storage location, you need to provide cloud authentication credentials. For Amazon S3, use your Amazon access key ID (e.g., cred:AWS_ACCESS_KEY_ID). For Rackspace Cloud Files, use your Rackspace login username (e.g., cred:RACKSPACE_USERNAME).",
      "display_name": "Dump Storage Account ID",
      "type": "string",
      "choice": [

      ],
      "calculated": false
    },
    "db/backup/restore_version_check": {
      "required": "optional",
      "default": "true",
      "recipes": [
        "db::do_primary_restore",
        "db::do_secondary_restore",
        "db::do_primary_init_slave",
        "db::do_secondary_init_slave",
        "db::do_init_slave_at_boot",
        "do_primary_restore_and_become_master",
        "do_secondary_restore_and_become_master"
      ],
      "description": "A variable to allow to restore from a backup performed on a different version of the DB software. Make sure you fully understand the implications of cross-version restoration.  Set to false to skip version checking.",
      "display_name": "Backup restore version check",
      "type": "string",
      "choice": [
        "true",
        "false"
      ],
      "calculated": false
    },
    "db/replication/user": {
      "required": "required",
      "recipes": [
        "db::setup_replication_privileges",
        "db::do_primary_restore_and_become_master",
        "db::do_secondary_restore_and_become_master",
        "db::do_init_and_become_master",
        "db::do_promote_to_master",
        "db::do_primary_init_slave",
        "db::do_secondary_init_slave",
        "db::do_init_slave_at_boot"
      ],
      "description": "The username of the database user that has 'replication' privileges (e.g., cred:DBREPLICATION_USER).",
      "display_name": "Database Replication Username",
      "type": "string",
      "choice": [

      ],
      "calculated": false
    },
    "db/dns/slave/id": {
      "required": "required",
      "recipes": [
        "db::do_set_dns_slave_private_ip"
      ],
      "description": "The unique identifier that is associated with the DNS A record of a slave server.  The unique identifier is assigned by the DNS provider when you create a dynamic DNS A record. This ID is used to update the associated A record with the private IP address of a slave server when this recipe is run.  If you are using DNS Made Easy as your DNS provider, a 7-digit number is used (e.g., 4403234).",
      "display_name": "Database Slave DNS Record ID",
      "type": "string",
      "choice": [

      ],
      "calculated": false
    },
    "db/dns/slave/fqdn": {
      "required": "optional",
      "recipes": [
        "db::do_set_dns_slave_private_ip"
      ],
      "description": "The fully qualified domain name for a slave database server (e.g., text:db-slave.example.com).",
      "display_name": "Database Slave FQDN",
      "type": "string",
      "choice": [

      ],
      "calculated": false
    },
    "db/dump/storage_account_provider": {
      "required": "required",
      "recipes": [
        "db::do_dump_import",
        "db::do_dump_export",
        "db::do_dump_schedule_enable"
      ],
      "description": "Location where the dump file will be saved. Used by dump recipes to back up to Amazon S3 or Rackspace Cloud Files.",
      "display_name": "Dump Storage Account Provider",
      "type": "string",
      "choice": [
        "s3",
        "cloudfiles",
        "cloudfilesuk",
        "SoftLayer_Dallas",
        "SoftLayer_Singapore",
        "SoftLayer_Amsterdam"
      ],
      "calculated": false
    },
    "db/terminate_safety": {
      "required": "optional",
      "default": "Override the dropdown and set to \"off\" to really run this recipe",
      "recipes": [
        "db::do_delete_volumes_and_terminate_server"
      ],
      "description": "Prevents the accidental running of the db::do_teminate_server recipe. This recipe will only run if this input variable is overridden and set to \"off\".",
      "display_name": "Terminate Safety",
      "type": "string",
      "choice": [
        "Override the dropdown and set to \"off\" to really run this recipe"
      ],
      "calculated": false
    }
  },
  "replacing": {
  },
  "dependencies": {
    "db_mysql": [

    ],
    "block_device": [

    ],
    "db_postgres": [

    ],
    "sys_firewall": [

    ],
    "rightscale": [

    ]
  },
  "name": "db",
  "groupings": {
  },
  "version": "0.2.0",
  "recommendations": {
  }
}